---
id: amd-dev-challenge-2025
title: "AMD Developer Challenge 2025: Inference Sprint"
date: 2025-04-15
category: "AMD Developer Challenge"
---

We are excited to announce the $100K competition hosted by
[@AMD](https://x.com/AMD) as part of the first round of our GPU kernel leaderboard!
The theme is writing LLM inference kernels on AMD MI300s, provided for free through the
[GPU MODE Discord](https://www.discord.gg/gpumode).

You (and anyone around the world) can participate for FREE by signing up [here](https://www.datamonsters.com/amd-developer-challenge-2025#wf-form-AMD-Email-Form).
The format consists of three kernels that are core to DeepSeek's LLM inference:
**FP8 GEMM**, **Multi-Head Latent Attention**, and **Fused MOE**!

Competitors will target the AMD MI300 using Triton, but other DSLs and languages that target AMD hardware are permitted!
Participants can form teams of three when competing, and prizes will be awarded based on team rankings averaged over the three kernels.

Special thanks to [@AMD](https://x.com/AMD), [@indianspeedster](https://x.com/indianspeedster), and the amazing GPU MODE Project Popcorn core devs:
[@a1zhang](https://x.com/a1zhang), [@m_sirovatka](https://x.com/m_sirovatka), [@marksaroufim](https://x.com/marksaroufim), **ngc92 (Erik S.)**, and [@b9r5](https://github.com/b9r5) for making this competition possible.

We're very excited to accelerate AI research by building on kernels, and we're super grateful for all of the support from the community!

If you're interested in collaborating with us on future competitions or kernels you think are important, definitely reach out to any one of us on the Popcorn team!

Get started now! The first kernel is the [FP8 Groupwise GEMM](/static/pdfs/2025-amd-dev-fp8-gemm.pdf).

![2025 AMD Developer Challenge: Inference Sprint](/static/images/2025-amd-dev-challenge.jpeg)
